\documentclass[chi_draft]{sigchi}
%\documentclass{sigchi}

% Use this command to override the default ACM copyright statement
% (e.g. for preprints).  Consult the conference website for the
% camera-ready copyright statement.

%% EXAMPLE BEGIN -- HOW TO OVERRIDE THE DEFAULT COPYRIGHT STRIP -- (July 22, 2013 - Paul Baumann)
% \toappear{Permission to make digital or hard copies of all or part of this work for personal or classroom use is      granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \\
% {\emph{CHI'14}}, April 26--May 1, 2014, Toronto, Canada. \\
% Copyright \copyright~2014 ACM ISBN/14/04...\$15.00. \\
% DOI string from ACM form confirmation}
%% EXAMPLE END -- HOW TO OVERRIDE THE DEFAULT COPYRIGHT STRIP -- (July 22, 2013 - Paul Baumann)

% Arabic page numbers for submission.  Remove this line to eliminate
% page numbers for the camera ready copy
% \pagenumbering{arabic}

% Load basic packages
\usepackage{balance}  % to better equalize the last page
\usepackage{graphics} % for EPS, load graphicx instead 
\usepackage[T1]{fontenc}
\usepackage{txfonts}
\usepackage{mathptmx}
\usepackage[pdftex]{hyperref}
\usepackage{color}
\usepackage{booktabs}
\usepackage{textcomp}
% Some optional stuff you might like/need.
\usepackage{microtype} % Improved Tracking and Kerning
% \usepackage[all]{hypcap}  % Fixes bug in hyperref caption linking
\usepackage{ccicons}  % Cite your images correctly!
% \usepackage[utf8]{inputenc} % for a UTF8 editor only

% If you want to use todo notes, marginpars etc. during creation of your draft document, you
% have to enable the "chi_draft" option for the document class. To do this, change the very first
% line to: "\documentclass[chi_draft]{sigchi}". You can then place todo notes by using the "\todo{...}"
% command. Make sure to disable the draft option again before submitting your final document.
\usepackage{todonotes}

% Paper metadata (use plain text, for PDF inclusion and later
% re-using, if desired).  Use \emtpyauthor when submitting for review
% so you remain anonymous.
\def\plaintitle{Visual Estimation of Trend in Scatterplot Visualizations}
\def\plainauthor{Removed for Review}
\def\emptyauthor{}
\def\plainkeywords{Information Visualization, Graphical Perception, Regression}
\def\plaingeneralterms{Visualization}

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{
    \def\UrlFont{\sf}
  }{
    \def\UrlFont{\small\bf\ttfamily}
  }}
\makeatother
\urlstyle{leo}

% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, to give it a
% fighting chance of not being over-written, since its job is to
% redefine many LaTeX commands.
\definecolor{linkColor}{RGB}{6,125,233}
\hypersetup{%
  pdftitle={\plaintitle},
% Use \plainauthor for final version.
%  pdfauthor={\plainauthor},
  pdfauthor={\emptyauthor},
  pdfkeywords={\plainkeywords},
  bookmarksnumbered,
  pdfstartview={FitH},
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=black,
  urlcolor=linkColor,
  breaklinks=true,
}

% create a shortcut to typeset table headings
% \newcommand\tabhead[1]{\small\textbf{#1}}

% End of preamble. Here it comes the document.
\begin{document}

\title{\plaintitle}

\numberofauthors{2}
\author{%
%  \alignauthor{Michael Correll\\
%    \affaddr{University of Washington}\\
%    \email{mcorrell@cs.washington.edu}}\\
%  \alignauthor{Jeffrey Heer\\
%    \affaddr{University of Washington}\\
%    \email{jheer@cs.washington.edu}}\\
}

\maketitle

\begin{abstract}
Observing trends in bivariate data, or predicting the future values of data, is a common task for viewers of visualizations. Yet, designer do not always explicitly include trend lines and other relevant statistical modeling information in charts. Thus, viewers must often perform \emph{regression by eye} --- they estimate the trend of data through the values alone. If viewer performance at this task is sufficiently poor, or if certain designs introduce unacceptable bias, then designers will need to rethink how to communicate trends to the general audience. In this work, we present a series of crowd-sourced experiments examining regression by eye, investigating both viewer performance at estimation of trends in bivariate data, and potential sources of bias in these estimations. Our findings indicate that, while viewers can accurately estimate trends in many standard visualizations of bivariate data, certain visual designs (such as the visual asymmetry of area charts) and certain features of the data (such as the presence of outliers) result in visual estimations that do not align with basic statistical models of regression.
\end{abstract}

\category{H.5.m.}{Information Interfaces and Presentation
  (e.g. HCI)}{Miscellaneous}

\keywords{\plainkeywords}

\section{Introduction}

%motivation here is poor. needs another turn of the crank.

\todo{This motivation needs work. Also some redundancies}

One of the motivating examples for the power of information visualization is Anscombe's quartet\cite{anscombe1973graphs}, a set of four bivariate sets with nearly identical summary statistics, but with drastically different patterns when drawn as a scatterplot. Implicit in this example is that people have a robust ability to recognize visual patterns in information visualizations and, moreover, to employ this pattern recognition ability towards statistical ends. That is, an underlying assumption in information visualization is that people have the ability to \emph{visually} estimate \emph{statistical} quantities of interest, and can perform at least rough analogs of statistical tasks including model selection, identification of outliers, and estimation of summary statistics, entirely through visual inspection. Knowing the limits of this ``estimation by eye,'' is important for designers of information visualizations seeking to communicate statistical quantities, especially to the general audience. More than a mere mismatch between the statistical values which the designer intends to communicate, and the ability of viewers to estimate those values, there is also the possibility of \emph{bias}--- the design of visualizations may cause viewers to over- or underestimate task-relevant values.

The estimation of trends in bivariate data is an important analytical task, as it is the basis for many factors relevant to decision-making, such as prediction, imputation, and comparison. Unfortunately, model information is not always explicitly provided by designers of visualizations. When designers do include trend information (for instance, by annotating a scatterplot with a line of best fit), other statistics relevant to the model (such as $r$ values or confidence bands) may be absent. Even if designers specifically include all relevant information, the audience may lack the statistical expertise to interpret these values. As a further complication, visual presentation of bivariate data can influence the types of analysis made by viewers (for instance, viewers may be more likely to consider trends with line charts, and to compare individual values with bar charts \cite{zacks1999bars}). These design choices can also introduce bias (for instance, the visual asymmetry of bars can cause ``within-the-bar'' bias \cite{newman2012bar}). Designers need guidance both on how much accuracy they can expect from viewers making trend estimations ``by eye,'' as well as whether or not different types of bivariate visualizations can bias these estimations.

In this work, we describe a series of crowd-sourced studies on the visual estimation of trend in common bivariate visualizations (scatterplots, area charts, and linegraphs). We report on the results of three studies, investigating estimation of trend slope, trend intercept, and the effect of outliers. We find that, while in most cases viewers make accurate estimations of trends, area charts introduce systematic underestimation of trend intercept, and outliers introduce ambiguity in how trends are estimated. These results suggest that there are several areas where human judgments diverge from the fitted models generated by techniques such as Ordinary Least Squares (OLS), and that the design of bivariate visualizations can introduce additional biases in these judgments.

\section{Related Work}

While there is a great deal of foundational work in visualization and graphical perception dealing with the estimation of individual values in visualizations (such as the height of the bar in a bar chart, or the angle of a line in a linegraph), there is comparatively little work on how viewers of visualizations perceive aggregate statistical quantities. Ariely~\cite{ariely2001seeing} suggests that, in concert with the perception of individual objects, we also collect information about the \emph{ensemble} properties of visual displays. Szafir et al.~\cite{szafir2016four} suggest that this \emph{ensemble coding} can afford the accurate estimation of \emph{summary statistics} in visualizations. However, visualizations with good performance for summary tasks may not result in good performance at point tasks, and vice versa~\cite{albers2014task,fuchs2013evaluation}. 

Scatterplots are a standard design for visualization bivariate data, with a multitude of design parameters that affect their suitability for aggregate tasks~\cite{cleveland1984many}. Prior work has confirmed that viewers can make use of scatterplots to perform prediction tasks (which tacitly rely on estimation of trend) in ways that are robust to both noise~\cite{harvey1997effects} and problem frame~\cite{lewandowsky2011popular}. However, the heuristics used when performing these prediction tasks (such as the anchor-and-adjust method~\cite{bolger1993context}) can introduce biases. Similarly, the design of scatterplots (for instance, the decision to encode class membership with color or with shape) can also impact performance at aggregate tasks~\cite{gleicher2013perception,lewandowsky1989discriminating}. The aspect ratio of graphs can also bias judgments about trend~\cite{beattie2002impact}--- wider aspect ratios can cause viewers to underestimate the severity of effects, when compared to narrower charts. Another bias in prediction tasks is the ``within-the-bar'' bias \cite{newman2012bar}: for visually asymmetric visualizations such as bar charts, points contained within the visual area of the bar glyph are perceived as likelier than those outside the glyph. 

Recent work in the visualization community has focused on the perception of correlation in scatterplots. Rensink et al.~\cite{rensink2010perception} show that viewers can estimate correlation with some accuracy in scatterplots. Harrison et al. \cite{harrison2014ranking} extend this finding to other visualization types, although a reanalysis by Kay \& Heer~\cite{kay2016beyond} indicates that, for many of the more esoteric bivariate visualizations, performance at this task is poor. Estimation of correlation can also be biased by the design of scales~\cite{cleveland1982variables}--- the whitespace and aspect ratio changes introduced by expanding the scale of the axes can cause overestimation of correlation.

Our task of trend estimation combines elements of both prediction and correlation estimation tasks. As with prediction, there is not necessarily an unambiguous ``correct'' estimation of trend (different modeling and regression methods can produce different trend lines). As with correlation, viewers must make holistic judgments about the dataset in a way that (as per Harrison et al.) likely relies on a set of key visual proxies. And, as with both tasks, we believe that trend estimation can be biased through conscious or unconscious design choices.  

\section{General Methods}

In order to assess the ability of viewers of visualizations to estimate trend, we conducted a series of three crowd-sourced experiments on Amazon's Mechanical Turk platform. Crowd-sourcing is a valuable tool for graphical perception experiments, as it affords flexibilities and scales that would be difficult for in-person experiments~\cite{heer2010crowdsourcing}. Crowd-sourced graphical perception experiments produce results that are largely in keeping with prior, lab-based work~\cite{talbot2014four}.


We limited the participant pool to subjects from within the United States, with a prior task approval rating of at least 90\%. For all experiments, we included stimuli where the trend line was visible as attention checks and for validation. We excluded participants with poor performance on these stimuli. Based on timings from internal piloting, we paid each participant \$2 for their participation, for an intended rate of \$8/hour. 

We generated the scatterplots by first generating the horizontal position of points through banded Monte Carlo sampling, ensuring that, while the distribution of points in $X$ appeared uniform, at least $X/b$ points appear in each of the $b$ bands. We performed rejection sampling to ensure that no two points overlapped by more than half their radius in the resulting 600x1050 image. Next, we created a set of residual values, sampled evenly from discretized gaussian. This procedure ensured that the actual and intended bandwidth and standard deviation of residual values is precise. This set was permuted, and then applied to the points along with a target linear trend. As heteroskedasticity introduced through permutation could alter the actual linear trend away from the target trend, we performed rejection sampling to ensure that the trend of the resulting points were within $10^{-7}$ of the target trend. We reused this residuals across all different trend types (linear, quadratic, or trigonometric). Except where noted, we selected trend lines that were centered in the image: that is, for a horizontal data extent of $[0,1]$, $f(0.5) = 0.5$.

\todo{Add figure of experimental apparatus}

In all experiments, participants entered in information using a slider without tick marks, in order to avoid anchoring effects \cite{matejka2016effect}. Moving the slider adjusts a purple trend line by adjusting its slope (in experiments 1 and 3) or its y-intercept (in experiment 2). After moving the slider, participants had to confirm their choice of trend line. For validation, certain trials contained the actual (OLS) trend line. We excluded the results of participants with poor performance on these validation questions. 

\subsection{Participants}

\todo{48 per experiment, report all demographics here rather than in experiment subsections.}

\section{1. Estimation of Slope is Reliable \\ Across Visualizations}


We presented participants with a series of bivariate visualizations, and adjusted a slider to fit the perceived trend in the points. Visualizations were one of a scatterplot, linegraph, or area chart (with the filled area below the line). Visualizations consisted of one of three types of trend (linear, quadratic, or trigonometric). For each stimulus, participants adjusted a slider that controlled the slope of a rendered trend line (or, in the case of the quadratic trends, the curvature, or the trigonometric, the positive/negative amplitude).


\subsection{Hypotheses}
\subsection{Results}
\subsection{Discussion}

\section{2. Estimation of Intercept is Subject to \\ ``Within The Bar'' Bias}

As with the previous experiment, we presented participants with a series of bivariate visualizations. However, instead of estimating the \emph{slope} of the points, participants estimated the \emph{y intercept} of the trend line. For each trial, we added a uniform offset to the points in the bivariate visualization in the data range $[-0.25,0.25]$. The rendered trend line was initially placed with the correct slope, and such that $f(0.5)=0.5$ in data space. Participants adjusted a slider controlling the vertical offset of this trend line. 

\subsection{Hypotheses}
\subsection{Results}
\subsection{Discussion}

\section{3. Estimation of Slope is Sensitive to Outliers}

This experiment was largely identical to experiment 1 above, except we designated 0, 5, 10, or 15 points at the very beginning, middle, or end of the series as outliers, and placed them randomly in the top or bottom 10\% of the visual area of the visualization (whichever was furthest from the trend line). We then calculated the outlier-sensitive line of best fit, as well as the intersection between this new trend line and the original, intended trend line. As with experiment 1, the participants controlled the slope of a rendered trend line with a slider. However, rather than being placed such that $f(0.5)=0.5$, we offset the trend line to the intersection of the robust (without outliers) and non-robust (including outliers) trend line. This allowed participants to express both types of fit with the same slider interaction, while affording estimations beyond a simple interpolation of both trends.

\subsection{Hypotheses}
\subsection{Results}
\subsection{Discussion}

\section{Discussion}
\subsection{Limitations \& Future Work}
\subsection{Conclusion}
\section{Acknowledgments}

Omitted for review.

% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
\balance{}


% REFERENCES FORMAT
% References must be the same font size as other body text.
\bibliographystyle{SIGCHI-Reference-Format}
\bibliography{sample}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
